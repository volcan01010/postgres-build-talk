<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<meta name="description" content="Presentation slides for PostgreSQL Build, December 2021">
		<meta name="author" content="Dr John A Stevenson">

		<title>How many Postgres is too many?</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/bgs.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
<section>
	<section>
		<h4>How many Postgres is too many?</h4>
		<p><span class="small">An infrastructure-as-code approach to PostgreSQL-backed IoT sensor data sharing</span></p>
		<p>
		<span class="small"><a href="https://twitter.com/volcan01010">Dr John A Stevenson</a> / <a href="https://twitter.com/volcan01010">@volcan01010</a></span>
		</p>
		<a href="https://www.bgs.ac.uk"><img src="images/BGS-Logo-Pos-RGB.svg" width=400 style="background:white; border:15px solid white; box-shadow:none;"></a>
		<aside data-markdown class="notes">
		The aim of this talk is to describe architecture of BGS Sensor Data Service, the tools that we used to create it and some hopefully helpful hints that we learned in the process.
		</aside>
	</section>
	<section data-markdown>
		+ Background
		+ Single server configuration
		+ Multi-environments and replication
		+ Questions for discussion
	</section>
		<aside data-markdown class="notes">
		Our approach is different to the cloud-native, Kubernetes-based setups described in the other talks.
		Hopefully there will time for feedback and discussion on it at the end.
		</aside>
</section>

<section>
	<section>
		<h4>About BGS</h4>
		<blockquote>"Our mission is to provide impartial and independent geoscience advice and data."</blockquote>
		<ul>
		<li>Work with academics, governments, industry and the public</li>
		<li>Digital division has 10 years of making digital data available e.g. via <a href="http://onegeology.org/">OneGeology</a> and <a href="https://www.bgs.ac.uk/geological-data/opengeoscience/">OpenGeoscience Portal</a>
		and contributions to standards for data sharing e.g. <a href="https://www.bgs.ac.uk/news/geosciml-data-standard-becomes-official/">GeoSciML</a></li>
		</ul>
	<aside data-markdown class="notes">
		We have 650 staff, 70 in Digital are professional software developers and database experts.
		This service is part of our recent approach of increasingly sharing data via APIs.
	</aside>
	</section>

	<section>
		<h4>BGS IT Infrastructure</h4>
		<ul>
		<li>Self-hosted virtual machines running on premises</li>
		<li>Long-standing corporate Oracle database</li>
		<li>Increasing use of PostgreSQL for microservices and collaborative projects</li>
		</ul>
	<aside data-markdown class="notes">
		Self-hosting our VMs means that we do not pay per minute; it is not expensive to run multiple servers with low loads.
		Microservices often bring their own PostgreSQL databases as part of the software stack.
		If we use PostgreSQL, we can share workflows with partners in academia or countries such as Kyrgyzstan and Uganda.
	</aside>
	</section>

	<section>
		<img class="stretch" src="images/glasgow_main_mine_working.png">
		<a href="https://ukgeos.ac.uk/observatories/glasgow">UK Geoenergy Observatories</a>
	<aside data-markdown class="notes">
		For the UKGEOS project, we have placed instruments down boreholes to create natural laboratories.
		UKGEOS Glasgow is investigating the use of water in abandoned coal mines to heat homes in a similar way to a ground source heat pump.
	</aside>
	</section>

	<section>
		<img class="stretch" src="images/sensor_data_graph.png">
		<a href="https://sensors.bgs.ac.uk">sensors.bgs.ac.uk</a>
	<aside data-markdown class="notes">
		The BGS Sensor Data Service allows the data to be accessed via an api.
		It is powered by FROST-Server, which is an open-source project serving the data via the Open Geospatial Consortium's SensorThings API standard.

		+ [API root](https://sensors.bgs.ac.uk/FROST-Server/v1.1)
		+ [Observed properties include water temperature](https://sensors.bgs.ac.uk/FROST-Server/v1.1/ObservedProperties)
		+ [Datastreams for water temperature in different locations](https://sensors.bgs.ac.uk/FROST-Server/v1.1/ObservedProperties(3)/Datastreams)
		+ [Observations for borehole GGA07](https://sensors.bgs.ac.uk/FROST-Server/v1.1/Datastreams(20)/Observations)

		The water temperature is around 11Â°C.
	</aside>
	</section>
</section>

<section>
	<section data-background-size="contain" data-background="images/001_just_postgres.png">
	<aside data-markdown class="notes">
		This is a PostgreSQL conference, so we should centre the talk around PostgreSQL.
		I like it because it is easy to create many instances, which gives flexiblity and scope for test environments.
		You will see this as the talk goes on.
	</aside>
	</section>

	<section>
		<h4>Running PostgreSQL in Docker</h4>
		<ul>
		<li>Images as small as 150 Mb, spin up in seconds</li>
		<li>Same on the server as on developer laptop</li>
		<li>Cluster settings are applied (e.g. pg_hba.conf) with setup scripts</li>
		<li>Configuration stored in /var/lib/postgres/data</li>
		</ul>
	<aside data-markdown class="notes">
		Docker is an easy way to install PostgreSQL.
		You can define scripts that are run when the container starts for the first time.
		These can be used to configure things such as the `pg_hba.conf`, which controls who can connect.
		All those settings are stored in `/var/lib/postgres/data`.
		Mounting `/var/lib/postgres/data` as a volume provides persistent data between changes to the container.
	</aside>
	</section>

	<section data-background-size="contain" data-background="images/001_just_postgres.png">
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/002_single_vm.png">
	<aside data-markdown class="notes">
		The runner services comprises a PostgreSQL database and FROST-Server instance running on a virtual machine.
		We use docker-compose to start the services together.
		FROST-Server connects to the database and creates the tables that it needs using Liquibase.
	</aside>
	</section>

	<section>
		<pre><code data-trim data-line-numbers="2,10,11,13,21,25,26">
services:
  db:
    image: .../frost-db:${FROST_DB_TAG}
    ...
    environment:
      POSTGRES_DB: frost_db
      POSTGRES_USER: ${FROST_DB_USER}
      POSTGRES_PASSWORD: ${FROST_DB_PASSWORD}
    ...
    volumes:
      - postgis_data:/var/lib/postgresql/data

  frost:
    image: .../frost-server:${FROST_API_TAG}
    ...
    environment:
      ...
      - persistence_db_url=jdbc:postgresql://db:5432/frost_db
      - persistence_db_username=${FROST_DB_USER}
      - persistence_db_password=${FROST_DB_PASSWORD}
    command: ["/wait_for_postgis.sh", "catalina.sh", "run"]
    depends_on:
      - db

volumes:
  postgis_data:
		</code></pre>
		docker-compose.yml
	<aside data-markdown class="notes">
		The docker-compose file describes the database (db) and FROST services.
		For the database, note the environment variables used to configure the superuser account and the volume to ensure that data persist.
		For the FROST Server, note the same credentials and the custom command to run when the container starts.
		This command ensures that the database is ready before FROST tries to create the tables.
	</aside>
	</section>

	<section>
		<pre><code data-trim>
#!/bin/sh
cmd="$@"
  
until PGPASSWORD=${persistence_db_password} psql \
  -h db -p 5432 -d frost_db -U ${persistence_db_username} \
  -c '\q'; do
  >&2 echo "Postgres is unavailable - sleeping"
  sleep 2
done

sleep 2  # Allow another 2 seconds for it to self-configure
>&2 echo "Postgres is up - executing command"
exec $cmd
		</code></pre>
		wait_for_postgres.sh
	<aside data-markdown class="notes">
		The `wait_for_postgres.sh` script captures the arguments passed to it in the `$cmd` variable.
		It then loops over a call to `psql -c '\q'`, which simply tries to connect to the database then quit.
		After the command succeeds, it calls `exec $cmd` to run the command in the remaining arguments.
	</aside>
	</section>

	<section>
		<pre><code data-trim data-line-numbers="1,6,13,20">
- name: Copy host_files to deployment directory
  copy:
    src: host_files/
    dest: "{{ deploy_dir }}"

- name: Write .env file with environment variables for table creation
  copy:
    dest: "{{ deploy_dir }}/.env"
    content: "{{ env_file_content_for_setup }}"

...

- name: Reset database
  docker_compose:
    project_src: "{{ deploy_dir }}"
    state: absent
    remove_volumes: yes
  when: reset_database

- name: Call docker-compose up
  docker_compose:
    project_src: "{{ deploy_dir }}"
    state: present
    recreate: always
		</code></pre>
		deploy.yml (Ansible playbook)
	<aside data-markdown class="notes">
		We use Ansible to deploy the application and database to the server.
		Ansible is a server-configuration tool that can SSH onto a target machine and run scripts there.
		The scripts are declarative, so they define the end state rather than the stops to get there.
		They are also idempotent, which means they can be run repeatedly and always give the same result.

		The scripts copy across the `docker-compose.yml` file and create a `.env` file containing the environment variables.
		They then call `docker-compose up` to start the service.

		We have an extra step to reset the database, which can be triggered via an environment variable.
		This will drop the data volume and give us a fresh start when the service starts.
	</aside>
	</section>

	<section data-background-size="contain" data-background="images/002_single_vm.png">
	<aside data-markdown class="notes">
		Once our service is running, we need to populate it with some data.
	</aside>
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/003_single_vm_and_etl.png">
	<aside data-markdown class="notes">
		The sensor data are stored in the corporate Oracle database, where they are highly normalised and integrated with other internal data structures.
		We wrote a custom Python tool called `etlhelper` to transfer the data to the FROST servers.
		`etlhelper` solves two problems:

		+ It installs and configures the Oracle Instant Client on Linux, which can be a bit fiddly
		+ It provides a simple way to run a SQL query against a database and get the results back using Python

		`etlhelper` runs a query against Oracle and then posts the results to the FROST server via the API.
		Using the API allows FROST to take care of all the internal foreign table relationships.
		The asynchronous `aiohttp` Python library made inserting data much quicker.
	</aside>
	</section>

	<section>
		<blockquote>etlhelper is a Python library to simplify data transfer between databases</blockquote>
		<img class="stretch" src="images/etlhelper_image.png">
		<a href="https://github.com/BritishGeologicalSurvey/etlhelper">https://github.com/BritishGeologicalSurvey/etlhelper</a>
	<aside data-markdown class="notes">
		`etlhelper` is aimed at anyone who just wants to run a SQL query against a database and insert the results into another one.
		In the example above, it copies the data from the "src" table on "conn1" to the "exported" table on "conn2".
		Behind the scenes it handles things like cursors and transactions and transferring the data in chunks so that it doesn't take up too much space in memory.
		We open-sourced `etlhelper` two years ago, so you can look at it on GitHub and install it using `pip`.
	</aside>
	</section>
</section>

<section>
	<section data-background-size="contain" data-background="images/003_single_vm_and_etl.png">
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/004_add_environments.png">
	<aside data-markdown class="notes">
	</aside>
	</section>

	<section>
		<img class="stretch" src="images/pglog_table_screenshot.png">
		Logs exported as CSV can be queried as a foreign table
	</section>

	<section>
		<pre><code data-trim data-line-numbers="10,11">
services:
  db:
    image: .../frost-db:${FROST_DB_TAG}
    ...
    environment:
      POSTGRES_DB: frost_db
      POSTGRES_USER: ${FROST_DB_USER}
      POSTGRES_PASSWORD: ${FROST_DB_PASSWORD}
    ...
    command: ["postgres", "-c", "logging_collector=on", "-c", "log_destination=csvlog",
              "-c", "log_filename=postgresql"]
    volumes:
      - postgis_data:/var/lib/postgresql/data

volumes:
  postgis_data:
		</code></pre>
		postgresql.conf settings can be overridden at startup
	</section>

	<section data-background-size="contain" data-background="images/004_add_environments.png">
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/005_integration_test.png">
	<aside data-markdown class="notes">
	</aside>
	</section>

	<section>
		Jobs table update code written by test-driven development
		<pre><code data-trim>
./db/migrations/
âââ common
âÂ Â  âââ V001__Create_jobs_table.sql
âÂ Â  âââ V002__Create_job_stats_table.sql
âÂ Â  âââ V003__Create_roles.sql
âÂ Â  ...
âÂ Â  âââ V012__Log_to_table.sql
âââ hwlapidev001
âÂ Â  âââ flyway.conf
âÂ Â  âââ sql
âÂ Â      âââ V005__Configure_replication.sql
âÂ Â      âââ V007__Configure_replication_delete_provider.sql
âââ hwlapidev002
âÂ Â  âââ flyway.conf
âÂ Â  âââ sql
âÂ Â      âââ V005__Configure_replication.sql
âÂ Â      âââ V007__Configure_replication_delete_provider.sql
...
		</pre></code>
		Flyway is used to apply SQL scripts to configure databases
	</section>
	
	<section data-background-size="contain" data-background="images/005_integration_test.png">
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/006_add_replication.png">
	<aside data-markdown class="notes">
	</aside>
	</section>

	<section>
		<pre><code data-trim>
SELECT pglogical.create_node(
    node_name := 'stage001',
    dsn := 'host=xxxx port=5432 dbname=frost_db user=xxxx password=${pglogical_upd_password}');

SELECT pglogical.create_replication_set('frost_all');

SELECT pglogical.replication_set_add_table(
	set_name := 'frost_public',
	relation := '"DATASTREAMS"',
	row_filter := ' "PROPERTIES" ->> ''publish_yn'' = ''Y'' ');
	</pre></code>
	pglogical replication is configured via SQL commands
	</section>

	<section data-background-size="contain" data-background="images/006_add_replication.png">
	</section>
	<section data-transition="fade-in" data-background-size="contain" data-background="images/007_replication_test.png">
	<aside data-markdown class="notes">
	</aside>
	</section>

	<section>
		<pre><code data-trim>
# Create database, stopping here if it already exists

if psql -U frost_db_superuser -d frost_db \
    -c "CREATE DATABASE frost_db2 WITH OWNER frost_db_superuser;"
then
  echo "Created database frost_db2"
else
  echo "Database frost_db2 already exists"
  exit 0
fi

# Copy data
echo "Copying contents and configuration from frost_db"
pg_dump -U frost_db_superuser -d frost_db > /tmp/frost_db.sql
psql -U frost_db_superuser -d frost_db2 -f /tmp/frost_db.sql

# Tidy up
rm /tmp/frost_db.sql
		</pre></code>
	An idempotent script to clone a running database
	</section>

	<section>
		<pre><code data-trim>
hosts: dev
  tasks:
    - name: Create frost_db2 as copy of frost_db
      command: >
          docker-compose exec db /bin/bash /create_frost_db2.sh
      args:
        chdir: "{{ deploy_dir }}"
		</pre></code>
	Storing script in container keeps CI logic clean
	</section>

</section>

<section>
	<section data-background-size="contain" data-background="images/007_replication_test_desaturated.png">
		<h4>Questions for discussion</h4>
		<ul>
			<li>Is 10 PostgreSQLs too many?</a>
			<li>Is it common to use pglogical as part of ETL process?</li>
			<li>What are the pros/cons of using a database pool?</li>
			<li>What if we had to pay by the minute for servers?</li>
		</ul>
	</section>
	<section>
		<h4>Thank you</h4>
	</section>
</section>

	</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				width: 1152,
				height: 840,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
